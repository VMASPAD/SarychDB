mod modules;

use modules::server::start_server;
use std::env;

enum Mode {
    Server,
    Benchmark,
}

struct CliConfig {
    mode: Mode,
    port: Option<u16>,
    nodes: Option<usize>,
    threads: Option<usize>,
    silent: bool,
}

impl CliConfig {
    fn from_args(args: Vec<String>) -> Self {
        let mut mode = Mode::Server;
        let mut port = None;
        let mut nodes = None;
        let mut threads = None;
        let mut silent = false;

        let mut iter = args.into_iter().skip(1);
        while let Some(arg) = iter.next() {
            match arg.as_str() {
                "benchmark" => {
                    mode = Mode::Benchmark;
                }
                "--port" => {
                    if let Some(value) = iter.next() {
                        match value.parse::<u16>() {
                            Ok(num) => port = Some(num),
                            Err(_) => eprintln!(
                                "‚ö†Ô∏è  Invalid value for --port: {} (using default).",
                                value
                            ),
                        }
                    } else {
                        eprintln!("‚ö†Ô∏è  Missing value for --port (using default).");
                    }
                }
                "--nodes" => {
                    if let Some(value) = iter.next() {
                        match value.parse::<usize>() {
                            Ok(num) if num > 0 => nodes = Some(num),
                            Ok(_) => eprintln!(
                                "‚ö†Ô∏è  --nodes must be greater than 0 (using default)."
                            ),
                            Err(_) => eprintln!(
                                "‚ö†Ô∏è  Invalid value for --nodes: {} (using default).",
                                value
                            ),
                        }
                    } else {
                        eprintln!("‚ö†Ô∏è  Missing value for --nodes (using default).");
                    }
                }
                "--threads" => {
                    if let Some(value) = iter.next() {
                        match value.parse::<usize>() {
                            Ok(num) if num > 0 => threads = Some(num),
                            Ok(_) => eprintln!(
                                "‚ö†Ô∏è  --threads must be greater than 0 (using default)."
                            ),
                            Err(_) => eprintln!(
                                "‚ö†Ô∏è  Invalid value for --threads: {} (using default).",
                                value
                            ),
                        }
                    } else {
                        eprintln!("‚ö†Ô∏è  Missing value for --threads (using default).");
                    }
                }
                "--background" | "--silent" => {
                    silent = true;
                }

                "--foreground" => {
                    silent = false;
                }
                other => {
                    eprintln!("‚ö†Ô∏è  Unrecognized argument '{}' - ignoring.", other);
                }
            }
        }

        CliConfig {
            mode,
            port,
            nodes,
            threads,
            silent,
        }
    }
}

#[tokio::main]
async fn main() {
    let args: Vec<String> = env::args().collect();
    let config = CliConfig::from_args(args);

    // Configure thread pool if specified
    if let Some(threads) = config.threads {
        use modules::search::configure_thread_pool;
        configure_thread_pool(Some(threads));
        if !config.silent {
            println!("‚öôÔ∏è  Configured thread pool with {} threads", threads);
        }
    }

    match config.mode {
        Mode::Benchmark => run_benchmark_mode(config.nodes, config.silent).await,
        Mode::Server => run_server_mode(config.port, config.silent).await,
    }
}

async fn run_server_mode(port_override: Option<u16>, silent: bool) {
    let port = port_override
        .or_else(|| {
            env::var("PORT")
                .ok()
                .and_then(|value| value.parse::<u16>().ok())
        })
        .unwrap_or(3030);

    if !silent {
        println!("üåü SarychDB - Parallel Database System");
        println!("======================================");
        println!("üöÄ Starting server on port {}", port);
    }
    
    start_server(port).await;
}

async fn run_benchmark_mode(nodes_override: Option<usize>, silent: bool) {
    use std::time::Instant;
    use modules::search::{Item, load_json, split_nodes, centralized_search, sequential_search, parallel_search, smart_search, get_optimal_node_count};
    
    let optimal_nodes = get_optimal_node_count();
    let num_nodes = nodes_override.unwrap_or(optimal_nodes);
    
    if !silent {
        println!("üîß CPU has {} optimal cores available", optimal_nodes);
        println!("Running benchmark with {} nodes", num_nodes);
    }

    let data: Vec<Item> = load_json("500MB.json");
    let nodes = split_nodes(data, num_nodes);

    let queries = ["T206", "id", "TensorFlow"];

    for &query in &queries {
        if !silent {
            println!("\nüîé Benchmark for query: \"{}\"", query);
        }

        let start = Instant::now();
        let r1 = centralized_search(&nodes, query);
        let t1 = start.elapsed().as_millis();

        let start = Instant::now();
        let r2 = sequential_search(&nodes, query);
        let t2 = start.elapsed().as_millis();

        let start = Instant::now();
        let r3 = parallel_search(&nodes, query);
        let t3 = start.elapsed().as_millis();

        let start = Instant::now();
        let r4 = smart_search(&nodes, query);
        let t4 = start.elapsed().as_millis();

        if !silent {
            println!("Centralized: {} results in {} ms", r1.len(), t1);
            println!("Sequential multi-node: {} results in {} ms", r2.len(), t2);
            println!("Parallel multi-node: {} results in {} ms", r3.len(), t3);
            println!("Smart search (auto): {} results in {} ms ‚≠ê", r4.len(), t4);
        }
    }
}